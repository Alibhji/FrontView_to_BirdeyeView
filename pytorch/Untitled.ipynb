{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: torch\n",
      "Version: 1.4.0\n",
      "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
      "Home-page: https://pytorch.org/\n",
      "Author: PyTorch Team\n",
      "Author-email: packages@pytorch.org\n",
      "License: BSD-3\n",
      "Location: /home/ali/.virtualenvs/py37/lib/python3.7/site-packages\n",
      "Requires: \n",
      "Required-by: torchvision, timm, pretrainedmodels, efficientnet-pytorch, catalyst\n",
      "Collecting torchsummary\n",
      "  Using cached torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\n",
      "Installing collected packages: torchsummary\n",
      "Successfully installed torchsummary-1.5.1\n"
     ]
    }
   ],
   "source": [
    "! pip show torch\n",
    "! pip install torchsummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "          Linear-174                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 25,557,032\n",
      "Trainable params: 25,557,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.56\n",
      "Params size (MB): 97.49\n",
      "Estimated Total Size (MB): 384.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from  torchvision import models\n",
    "from torchsummary import summary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "\n",
    "resnet50=models.resnet50(pretrained=True).to(device)\n",
    "vgg = models.vgg16().to(device)\n",
    "# summary(vgg, (3, 224, 224))\n",
    "summary(resnet50, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class My_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(My_model, self).__init__()\n",
    "        resnet50 = models.resnet50(pretrained=True)\n",
    "        self.resnet50 = torch.nn.Sequential(*(list(resnet50.children())[:-1]))\n",
    "        \n",
    "        for param in self.resnet50.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.encode_front_bbox =  nn.Sequential(\n",
    "            torch.nn.Linear(4, 256),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=.25),\n",
    "            torch.nn.Linear(256, 256),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=.25),            \n",
    "            torch.nn.Linear(256, 256),\n",
    "            torch.nn.ReLU(inplace=True)           \n",
    "         )\n",
    "        \n",
    "        self.decode_to_birdeye_bbox =  nn.Sequential(\n",
    "            torch.nn.Linear(256+2048, 1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=.25),\n",
    "            torch.nn.Linear(1024, 1024),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=.25), \n",
    "            torch.nn.Linear(1024, 512),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=.25), \n",
    "            torch.nn.Linear(512, 256),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=.25), \n",
    "            torch.nn.Linear(256, 128),\n",
    "            torch.nn.ReLU(inplace=True),\n",
    "            torch.nn.Dropout(p=.25),\n",
    "            \n",
    "            torch.nn.Linear(128, 4),\n",
    "            torch.nn.Tanh(),\n",
    "           \n",
    "         )\n",
    "#         self.classifier = nn.Linear(4, 2)\n",
    "#         self.la\n",
    "        \n",
    "    def forward(self, croped_f_image , f_bbox):\n",
    "        batch = croped_f_image.shape[0]\n",
    "        x1 = self.resnet50(croped_f_image)\n",
    "        x1 = x1.view(batch, 2048)\n",
    "        \n",
    "        encoded_f_bbox = self.encode_front_bbox(f_bbox)\n",
    "        x1 = torch.cat((x1, encoded_f_bbox), dim=1)\n",
    "        out = self.decode_to_birdeye_bbox (x1)\n",
    "        \n",
    "        \n",
    "        \n",
    "#         x1 = self.norm_layer(x1)\n",
    "#         x = torch.cat((x1, x2), dim=1)\n",
    "#         x = self.classifier(F.relu(x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(My_model())\n",
    "# summary(My_model().to(device), (3, 224, 224) )\n",
    "\n",
    "model = My_model()\n",
    "t_in = torch.randn(1,3,224,224 )\n",
    "t_in2 = torch.randn(1,4)\n",
    "model(t_in,t_in2).shape\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, child in model.named_children():\n",
    "#     for name2, params in child.named_parameters():\n",
    "#         print(name, name2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-142          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-143          [-1, 512, 14, 14]               0\n",
      "          Conv2d-144            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-145            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-146            [-1, 512, 7, 7]               0\n",
      "          Conv2d-147           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-148           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-149           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-150           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-151           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-152           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-153            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-154            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-155            [-1, 512, 7, 7]               0\n",
      "          Conv2d-156            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-157            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-158            [-1, 512, 7, 7]               0\n",
      "          Conv2d-159           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-160           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-161           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-162           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-163            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-164            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-165            [-1, 512, 7, 7]               0\n",
      "          Conv2d-166            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-167            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-168            [-1, 512, 7, 7]               0\n",
      "          Conv2d-169           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-170           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-171           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-172           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-173           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-174           [-1, 2048, 1, 1]               0\n",
      "================================================================\n",
      "Total params: 23,508,032\n",
      "Trainable params: 23,508,032\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 286.57\n",
      "Params size (MB): 89.68\n",
      "Estimated Total Size (MB): 376.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, modelA):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.norm_layer = nn.AdaptiveAvgPool2d(1)\n",
    "#         self.classifier = nn.Linear(4, 2)\n",
    "#         self.la\n",
    "        \n",
    "    def forward(self, x1):\n",
    "        x1 = self.modelA(x1)\n",
    "        x1 = self.norm_layer(x1)\n",
    "#         x = torch.cat((x1, x2), dim=1)\n",
    "#         x = self.classifier(F.relu(x))\n",
    "        return x1\n",
    "  \n",
    "    \n",
    "# model = models.resnet152(pretrained=True)\n",
    "resnet50 = models.resnet50(pretrained=True)\n",
    "resnet50 = torch.nn.Sequential(*(list(resnet50.children())[:-1])).to(device)\n",
    "# print(newmodel)\n",
    "# summary(resnet50, (3, 224, 224))    \n",
    "    \n",
    "    \n",
    "    \n",
    "resnet50 = MyEnsemble(resnet50)\n",
    "summary(resnet50, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type object argument after * must be an iterable, not BatchNorm2d",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-02c2362e3a2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresnet50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: type object argument after * must be an iterable, not BatchNorm2d"
     ]
    }
   ],
   "source": [
    "resnet50 = models.resnet50(pretrained=True)\n",
    "\n",
    "print(torch.nn.Sequential(*(list(resnet50.children())[-9])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchviz\n",
      "  Using cached torchviz-0.0.1.tar.gz (41 kB)\n",
      "Requirement already satisfied: torch in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from torchviz) (1.4.0)\n",
      "Requirement already satisfied: graphviz in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from torchviz) (0.13.2)\n",
      "Building wheels for collected packages: torchviz\n",
      "  Building wheel for torchviz (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for torchviz: filename=torchviz-0.0.1-py3-none-any.whl size=3522 sha256=b203e37b3e9a7d035344d62b2d556e31b1ca0ba414a937fa61a143742c7d5959\n",
      "  Stored in directory: /home/ali/.cache/pip/wheels/10/7b/c8/3af79ec02e294a832c01037bcb38302bbcee0bb020dcbbbd3e\n",
      "Successfully built torchviz\n",
      "Installing collected packages: torchviz\n",
      "Successfully installed torchviz-0.0.1\n"
     ]
    }
   ],
   "source": [
    "! pip install graphviz\n",
    "! pip install  torchviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{139651348686960: 'conv1.weight', 139649785527184: 'bn1.weight', 139649785527984: 'bn1.bias', 139649785527904: 'bn1.running_mean', 139649783774256: 'bn1.running_var', 139649752169360: 'bn1.num_batches_tracked', 139649858835152: 'layer1.0.conv1.weight', 139649858834672: 'layer1.0.bn1.weight', 139651349476848: 'layer1.0.bn1.bias', 139651349476928: 'layer1.0.bn1.running_mean', 139651349476448: 'layer1.0.bn1.running_var', 139649783383216: 'layer1.0.bn1.num_batches_tracked', 139649785145456: 'layer1.0.conv2.weight', 139651350426880: 'layer1.0.bn2.weight', 139651306555984: 'layer1.0.bn2.bias', 139651435579584: 'layer1.0.bn2.running_mean', 139651306844240: 'layer1.0.bn2.running_var', 139649757753824: 'layer1.0.bn2.num_batches_tracked', 139651306768096: 'layer1.1.conv1.weight', 139649783353584: 'layer1.1.bn1.weight', 139649784811344: 'layer1.1.bn1.bias', 139651306486192: 'layer1.1.bn1.running_mean', 139651309028048: 'layer1.1.bn1.running_var', 139649752180848: 'layer1.1.bn1.num_batches_tracked', 139651437605424: 'layer1.1.conv2.weight', 139651348334704: 'layer1.1.bn2.weight', 139651348335744: 'layer1.1.bn2.bias', 139649858732112: 'layer1.1.bn2.running_mean', 139649783306032: 'layer1.1.bn2.running_var', 139649785174768: 'layer1.1.bn2.num_batches_tracked', 139649754219696: 'layer2.0.conv1.weight', 139651312359936: 'layer2.0.bn1.weight', 139651432653360: 'layer2.0.bn1.bias', 139651306953776: 'layer2.0.bn1.running_mean', 139651314525840: 'layer2.0.bn1.running_var', 139651314526240: 'layer2.0.bn1.num_batches_tracked', 139651350385040: 'layer2.0.conv2.weight', 139649858694512: 'layer2.0.bn2.weight', 139649783515728: 'layer2.0.bn2.bias', 139649783079792: 'layer2.0.bn2.running_mean', 139651348441040: 'layer2.0.bn2.running_var', 139651312471008: 'layer2.0.bn2.num_batches_tracked', 139651438651424: 'layer2.0.downsample.0.weight', 139651435622064: 'layer2.0.downsample.1.weight', 139649784702768: 'layer2.0.downsample.1.bias', 139649748041632: 'layer2.0.downsample.1.running_mean', 139651308895120: 'layer2.0.downsample.1.running_var', 139649783243712: 'layer2.0.downsample.1.num_batches_tracked', 139649783242832: 'layer2.1.conv1.weight', 139651436575792: 'layer2.1.bn1.weight', 139649784905232: 'layer2.1.bn1.bias', 139649756748368: 'layer2.1.bn1.running_mean', 139649783892720: 'layer2.1.bn1.running_var', 139649784910864: 'layer2.1.bn1.num_batches_tracked', 139649757216512: 'layer2.1.conv2.weight', 139651439313376: 'layer2.1.bn2.weight', 139651440390048: 'layer2.1.bn2.bias', 139649767594256: 'layer2.1.bn2.running_mean', 139651307238896: 'layer2.1.bn2.running_var', 139651307240976: 'layer2.1.bn2.num_batches_tracked', 139649784430096: 'layer3.0.conv1.weight', 139649784429616: 'layer3.0.bn1.weight', 139649784429296: 'layer3.0.bn1.bias', 139649784428656: 'layer3.0.bn1.running_mean', 139651434114176: 'layer3.0.bn1.running_var', 139651434112896: 'layer3.0.bn1.num_batches_tracked', 139649750083376: 'layer3.0.conv2.weight', 139651306835152: 'layer3.0.bn2.weight', 139651312261152: 'layer3.0.bn2.bias', 139649858864144: 'layer3.0.bn2.running_mean', 139651306196176: 'layer3.0.bn2.running_var', 139651306193616: 'layer3.0.bn2.num_batches_tracked', 139651306196496: 'layer3.0.downsample.0.weight', 139651351481632: 'layer3.0.downsample.1.weight', 139651351479632: 'layer3.0.downsample.1.bias', 139651307123408: 'layer3.0.downsample.1.running_mean', 139651307123088: 'layer3.0.downsample.1.running_var', 139651307123248: 'layer3.0.downsample.1.num_batches_tracked', 139651307122928: 'layer3.1.conv1.weight', 139649750100720: 'layer3.1.bn1.weight', 139649750098640: 'layer3.1.bn1.bias', 139649750098320: 'layer3.1.bn1.running_mean', 139649750100080: 'layer3.1.bn1.running_var', 139651351953648: 'layer3.1.bn1.num_batches_tracked', 139651351953808: 'layer3.1.conv2.weight', 139651307332544: 'layer3.1.bn2.weight', 139651307333264: 'layer3.1.bn2.bias', 139651307332064: 'layer3.1.bn2.running_mean', 139651307332224: 'layer3.1.bn2.running_var', 139651309890928: 'layer3.1.bn2.num_batches_tracked', 139651309888688: 'layer4.0.conv1.weight', 139651309887648: 'layer4.0.bn1.weight', 139651306476880: 'layer4.0.bn1.bias', 139649761205696: 'layer4.0.bn1.running_mean', 139649761202736: 'layer4.0.bn1.running_var', 139651352829216: 'layer4.0.bn1.num_batches_tracked', 139649758693168: 'layer4.0.conv2.weight', 139649758691728: 'layer4.0.bn2.weight', 139651437256288: 'layer4.0.bn2.bias', 139651437253648: 'layer4.0.bn2.running_mean', 139651437254688: 'layer4.0.bn2.running_var', 139651437252688: 'layer4.0.bn2.num_batches_tracked', 139649751433296: 'layer4.0.downsample.0.weight', 139649785127632: 'layer4.0.downsample.1.weight', 139649785128112: 'layer4.0.downsample.1.bias', 139649785127312: 'layer4.0.downsample.1.running_mean', 139649785127472: 'layer4.0.downsample.1.running_var', 139649785127152: 'layer4.0.downsample.1.num_batches_tracked', 139649783138576: 'layer4.1.conv1.weight', 139649783137616: 'layer4.1.bn1.weight', 139649783137136: 'layer4.1.bn1.bias', 139649783136656: 'layer4.1.bn1.running_mean', 139651306599920: 'layer4.1.bn1.running_var', 139651306598720: 'layer4.1.bn1.num_batches_tracked', 139651306599680: 'layer4.1.conv2.weight', 139651440787120: 'layer4.1.bn2.weight', 139651440783760: 'layer4.1.bn2.bias', 139651440786640: 'layer4.1.bn2.running_mean', 139651440856672: 'layer4.1.bn2.running_var', 139651440855712: 'layer4.1.bn2.num_batches_tracked', 139651440854432: 'fc.weight', 139651440853072: 'fc.bias'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def make_dot(var, params):\n",
    "    \"\"\" Produces Graphviz representation of PyTorch autograd graph\n",
    "    \n",
    "    Blue nodes are the Variables that require grad, orange are Tensors\n",
    "    saved for backward in torch.autograd.Function\n",
    "    \n",
    "    Args:\n",
    "        var: output Variable\n",
    "        params: dict of (name, Variable) to add names to node that\n",
    "            require grad (TODO: make optional)\n",
    "    \"\"\"\n",
    "    param_map = {id(v): k for k, v in params.items()}\n",
    "    print(param_map)\n",
    "    \n",
    "    node_attr = dict(style='filled',\n",
    "                     shape='box',\n",
    "                     align='left',\n",
    "                     fontsize='12',\n",
    "                     ranksep='0.1',\n",
    "                     height='0.2')\n",
    "    dot = Digraph(node_attr=node_attr, graph_attr=dict(size=\"12,12\"))\n",
    "    seen = set()\n",
    "    \n",
    "    def size_to_str(size):\n",
    "        return '('+(', ').join(['%d'% v for v in size])+')'\n",
    "\n",
    "    def add_nodes(var):\n",
    "        if var not in seen:\n",
    "            if torch.is_tensor(var):\n",
    "                dot.node(str(id(var)), size_to_str(var.size()), fillcolor='orange')\n",
    "            elif hasattr(var, 'variable'):\n",
    "                u = var.variable\n",
    "                node_name = '%s\\n %s' % (param_map.get(id(u)), size_to_str(u.size()))\n",
    "                dot.node(str(id(var)), node_name, fillcolor='lightblue')\n",
    "            else:\n",
    "                dot.node(str(id(var)), str(type(var).__name__))\n",
    "            seen.add(var)\n",
    "            if hasattr(var, 'next_functions'):\n",
    "                for u in var.next_functions:\n",
    "                    if u[0] is not None:\n",
    "                        dot.edge(str(id(u[0])), str(id(var)))\n",
    "                        add_nodes(u[0])\n",
    "            if hasattr(var, 'saved_tensors'):\n",
    "                for t in var.saved_tensors:\n",
    "                    dot.edge(str(id(t)), str(id(var)))\n",
    "                    add_nodes(t)\n",
    "    add_nodes(var.grad_fn)\n",
    "    return dot\n",
    "\n",
    "from torchvision import models\n",
    "inputs = torch.randn(1,3,224,224)\n",
    "resnet18 = models.resnet18()\n",
    "y = resnet18(Variable(inputs))\n",
    "# print(y)\n",
    "\n",
    "g = make_dot(y, resnet18.state_dict())\n",
    "g.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{139649783651696: 'resnet50.0.weight', 139649764723760: 'resnet50.1.weight', 139649764722880: 'resnet50.1.bias', 139649764724160: 'resnet50.1.running_mean', 139649764721440: 'resnet50.1.running_var', 139649764722080: 'resnet50.1.num_batches_tracked', 139649764724640: 'resnet50.4.0.conv1.weight', 139649764722720: 'resnet50.4.0.bn1.weight', 139649764722400: 'resnet50.4.0.bn1.bias', 139649764723200: 'resnet50.4.0.bn1.running_mean', 139649764720720: 'resnet50.4.0.bn1.running_var', 139649764721200: 'resnet50.4.0.bn1.num_batches_tracked', 139649764669712: 'resnet50.4.0.conv2.weight', 139649764669952: 'resnet50.4.0.bn2.weight', 139649764669872: 'resnet50.4.0.bn2.bias', 139649764669392: 'resnet50.4.0.bn2.running_mean', 139649764668912: 'resnet50.4.0.bn2.running_var', 139649764669072: 'resnet50.4.0.bn2.num_batches_tracked', 139649764670112: 'resnet50.4.0.conv3.weight', 139649764671232: 'resnet50.4.0.bn3.weight', 139649764668592: 'resnet50.4.0.bn3.bias', 139649764670272: 'resnet50.4.0.bn3.running_mean', 139649764668832: 'resnet50.4.0.bn3.running_var', 139649764669632: 'resnet50.4.0.bn3.num_batches_tracked', 139649783683184: 'resnet50.4.0.downsample.0.weight', 139649785232592: 'resnet50.4.0.downsample.1.weight', 139649785231152: 'resnet50.4.0.downsample.1.bias', 139649751677040: 'resnet50.4.0.downsample.1.running_mean', 139649751678640: 'resnet50.4.0.downsample.1.running_var', 139649751678320: 'resnet50.4.0.downsample.1.num_batches_tracked', 139649751676880: 'resnet50.4.1.conv1.weight', 139651307253840: 'resnet50.4.1.bn1.weight', 139649767636896: 'resnet50.4.1.bn1.bias', 139649767635616: 'resnet50.4.1.bn1.running_mean', 139649767635456: 'resnet50.4.1.bn1.running_var', 139649767635376: 'resnet50.4.1.bn1.num_batches_tracked', 139649767633536: 'resnet50.4.1.conv2.weight', 139649767634176: 'resnet50.4.1.bn2.weight', 139649767634576: 'resnet50.4.1.bn2.bias', 139649767636256: 'resnet50.4.1.bn2.running_mean', 139649767634256: 'resnet50.4.1.bn2.running_var', 139649767635296: 'resnet50.4.1.bn2.num_batches_tracked', 139649767636096: 'resnet50.4.1.conv3.weight', 139649767635056: 'resnet50.4.1.bn3.weight', 139649767635536: 'resnet50.4.1.bn3.bias', 139649767635696: 'resnet50.4.1.bn3.running_mean', 139649767635936: 'resnet50.4.1.bn3.running_var', 139649767632976: 'resnet50.4.1.bn3.num_batches_tracked', 139649743526480: 'resnet50.4.2.conv1.weight', 139649743525360: 'resnet50.4.2.bn1.weight', 139649743524960: 'resnet50.4.2.bn1.bias', 139649743525120: 'resnet50.4.2.bn1.running_mean', 139649743524480: 'resnet50.4.2.bn1.running_var', 139649743523920: 'resnet50.4.2.bn1.num_batches_tracked', 139649743524720: 'resnet50.4.2.conv2.weight', 139649764421216: 'resnet50.4.2.bn2.weight', 139649764421056: 'resnet50.4.2.bn2.bias', 139649764420896: 'resnet50.4.2.bn2.running_mean', 139649764419376: 'resnet50.4.2.bn2.running_var', 139649767612576: 'resnet50.4.2.bn2.num_batches_tracked', 139649767602048: 'resnet50.4.2.conv3.weight', 139649767601808: 'resnet50.4.2.bn3.weight', 139649767600848: 'resnet50.4.2.bn3.bias', 139649767602688: 'resnet50.4.2.bn3.running_mean', 139649767601088: 'resnet50.4.2.bn3.running_var', 139651308795536: 'resnet50.4.2.bn3.num_batches_tracked', 139651308795296: 'resnet50.5.0.conv1.weight', 139651308795376: 'resnet50.5.0.bn1.weight', 139651308797536: 'resnet50.5.0.bn1.bias', 139651308795776: 'resnet50.5.0.bn1.running_mean', 139651308793936: 'resnet50.5.0.bn1.running_var', 139651308795616: 'resnet50.5.0.bn1.num_batches_tracked', 139651308797296: 'resnet50.5.0.conv2.weight', 139651308794576: 'resnet50.5.0.bn2.weight', 139651308796336: 'resnet50.5.0.bn2.bias', 139651308796576: 'resnet50.5.0.bn2.running_mean', 139651308797856: 'resnet50.5.0.bn2.running_var', 139651308796416: 'resnet50.5.0.bn2.num_batches_tracked', 139649764636704: 'resnet50.5.0.conv3.weight', 139649764637104: 'resnet50.5.0.bn3.weight', 139649764637584: 'resnet50.5.0.bn3.bias', 139649764636944: 'resnet50.5.0.bn3.running_mean', 139649764636384: 'resnet50.5.0.bn3.running_var', 139649764637024: 'resnet50.5.0.bn3.num_batches_tracked', 139649764637904: 'resnet50.5.0.downsample.0.weight', 139649764635584: 'resnet50.5.0.downsample.1.weight', 139649764635264: 'resnet50.5.0.downsample.1.bias', 139649764638064: 'resnet50.5.0.downsample.1.running_mean', 139649764635984: 'resnet50.5.0.downsample.1.running_var', 139649764638384: 'resnet50.5.0.downsample.1.num_batches_tracked', 139651308013520: 'resnet50.5.1.conv1.weight', 139649764640160: 'resnet50.5.1.bn1.weight', 139649764640720: 'resnet50.5.1.bn1.bias', 139649764642240: 'resnet50.5.1.bn1.running_mean', 139649764640240: 'resnet50.5.1.bn1.running_var', 139649764639600: 'resnet50.5.1.bn1.num_batches_tracked', 139649764642000: 'resnet50.5.1.conv2.weight', 139649764641360: 'resnet50.5.1.bn2.weight', 139649764641280: 'resnet50.5.1.bn2.bias', 139649764642480: 'resnet50.5.1.bn2.running_mean', 139649764642640: 'resnet50.5.1.bn2.running_var', 139649764641040: 'resnet50.5.1.bn2.num_batches_tracked', 139649764639920: 'resnet50.5.1.conv3.weight', 139649764640000: 'resnet50.5.1.bn3.weight', 139649761167952: 'resnet50.5.1.bn3.bias', 139649764443152: 'resnet50.5.1.bn3.running_mean', 139649764443072: 'resnet50.5.1.bn3.running_var', 139649764446112: 'resnet50.5.1.bn3.num_batches_tracked', 139649764442912: 'resnet50.5.2.conv1.weight', 139649764443472: 'resnet50.5.2.bn1.weight', 139649764443632: 'resnet50.5.2.bn1.bias', 139651440837408: 'resnet50.5.2.bn1.running_mean', 139651440840048: 'resnet50.5.2.bn1.running_var', 139651309187312: 'resnet50.5.2.bn1.num_batches_tracked', 139649743445920: 'resnet50.5.2.conv2.weight', 139649743443360: 'resnet50.5.2.bn2.weight', 139649743444640: 'resnet50.5.2.bn2.bias', 139649743442560: 'resnet50.5.2.bn2.running_mean', 139649743443440: 'resnet50.5.2.bn2.running_var', 139649743445600: 'resnet50.5.2.bn2.num_batches_tracked', 139649764924064: 'resnet50.5.2.conv3.weight', 139649764925344: 'resnet50.5.2.bn3.weight', 139651306835152: 'resnet50.5.2.bn3.bias', 139651306478960: 'resnet50.5.2.bn3.running_mean', 139651307332544: 'resnet50.5.2.bn3.running_var', 139651307332064: 'resnet50.5.2.bn3.num_batches_tracked', 139649750098320: 'resnet50.5.3.conv1.weight', 139649750101200: 'resnet50.5.3.bn1.weight', 139649750098800: 'resnet50.5.3.bn1.bias', 139651307123248: 'resnet50.5.3.bn1.running_mean', 139651307123408: 'resnet50.5.3.bn1.running_var', 139651351479632: 'resnet50.5.3.bn1.num_batches_tracked', 139651351481712: 'resnet50.5.3.conv2.weight', 139651434112896: 'resnet50.5.3.bn2.weight', 139651434113056: 'resnet50.5.3.bn2.bias', 139649764533504: 'resnet50.5.3.bn2.running_mean', 139649764533824: 'resnet50.5.3.bn2.running_var', 139649764532304: 'resnet50.5.3.bn2.num_batches_tracked', 139651306255376: 'resnet50.5.3.conv3.weight', 139651436622624: 'resnet50.5.3.bn3.weight', 139649783445776: 'resnet50.5.3.bn3.bias', 139651306654768: 'resnet50.5.3.bn3.running_mean', 139649783729680: 'resnet50.5.3.bn3.running_var', 139651440640160: 'resnet50.5.3.bn3.num_batches_tracked', 139649767593376: 'resnet50.6.0.conv1.weight', 139649767595536: 'resnet50.6.0.bn1.weight', 139649767592976: 'resnet50.6.0.bn1.bias', 139649767594496: 'resnet50.6.0.bn1.running_mean', 139649767595216: 'resnet50.6.0.bn1.running_var', 139649767593936: 'resnet50.6.0.bn1.num_batches_tracked', 139651440390048: 'resnet50.6.0.conv2.weight', 139649783891280: 'resnet50.6.0.bn2.weight', 139649756748208: 'resnet50.6.0.bn2.bias', 139649784905232: 'resnet50.6.0.bn2.running_mean', 139649783242832: 'resnet50.6.0.bn2.running_var', 139651308896160: 'resnet50.6.0.bn2.num_batches_tracked', 139651308893680: 'resnet50.6.0.conv3.weight', 139649748041632: 'resnet50.6.0.bn3.weight', 139649784702768: 'resnet50.6.0.bn3.bias', 139651348441200: 'resnet50.6.0.bn3.running_mean', 139651348441040: 'resnet50.6.0.bn3.running_var', 139649783515568: 'resnet50.6.0.bn3.num_batches_tracked', 139651432654880: 'resnet50.6.0.downsample.0.weight', 139649783306032: 'resnet50.6.0.downsample.1.weight', 139649858732112: 'resnet50.6.0.downsample.1.bias', 139649752180368: 'resnet50.6.0.downsample.1.running_mean', 139649752180848: 'resnet50.6.0.downsample.1.running_var', 139651309028048: 'resnet50.6.0.downsample.1.num_batches_tracked', 139649783353584: 'resnet50.6.1.conv1.weight', 139651435580064: 'resnet50.6.1.bn1.weight', 139651435579584: 'resnet50.6.1.bn1.bias', 139649785145456: 'resnet50.6.1.bn1.running_mean', 139651349476048: 'resnet50.6.1.bn1.running_var', 139651349476448: 'resnet50.6.1.bn1.num_batches_tracked', 139649858836752: 'resnet50.6.1.conv2.weight', 139649752169360: 'resnet50.6.1.bn2.weight', 139649783774256: 'resnet50.6.1.bn2.bias', 139649785525264: 'resnet50.6.1.bn2.running_mean', 139649785527984: 'resnet50.6.1.bn2.running_var', 139651348686960: 'resnet50.6.1.bn2.num_batches_tracked', 139651440853072: 'resnet50.6.1.conv3.weight', 139651440856512: 'resnet50.6.1.bn3.weight', 139651440783440: 'resnet50.6.1.bn3.bias', 139651440783920: 'resnet50.6.1.bn3.running_mean', 139651440783760: 'resnet50.6.1.bn3.running_var', 139651440785680: 'resnet50.6.1.bn3.num_batches_tracked', 139651306599200: 'resnet50.6.2.conv1.weight', 139649783137776: 'resnet50.6.2.bn1.weight', 139649783137136: 'resnet50.6.2.bn1.bias', 139649783138576: 'resnet50.6.2.bn1.running_mean', 139651437253888: 'resnet50.6.2.bn1.running_var', 139651437255648: 'resnet50.6.2.bn1.num_batches_tracked', 139651437253648: 'resnet50.6.2.conv2.weight', 139649785128432: 'resnet50.6.2.bn2.weight', 139649785127152: 'resnet50.6.2.bn2.bias', 139649785127312: 'resnet50.6.2.bn2.running_mean', 139649785127632: 'resnet50.6.2.bn2.running_var', 139649784332848: 'resnet50.6.2.bn2.num_batches_tracked', 139649751436176: 'resnet50.6.2.conv3.weight', 139651350115184: 'resnet50.6.2.bn3.weight', 139651350117904: 'resnet50.6.2.bn3.bias', 139649758693408: 'resnet50.6.2.bn3.running_mean', 139649758693168: 'resnet50.6.2.bn3.running_var', 139651352828016: 'resnet50.6.2.bn3.num_batches_tracked', 139651309887648: 'resnet50.6.3.conv1.weight', 139651309891008: 'resnet50.6.3.bn1.weight', 139651309889088: 'resnet50.6.3.bn1.bias', 139651351953808: 'resnet50.6.3.bn1.running_mean', 139651351955088: 'resnet50.6.3.bn1.running_var', 139651351955408: 'resnet50.6.3.bn1.num_batches_tracked', 139651436975680: 'resnet50.6.3.conv2.weight', 139651306196496: 'resnet50.6.3.bn2.weight', 139651306196176: 'resnet50.6.3.bn2.bias', 139651306195376: 'resnet50.6.3.bn2.running_mean', 139651306195696: 'resnet50.6.3.bn2.running_var', 139651306193296: 'resnet50.6.3.bn2.num_batches_tracked', 139649750084176: 'resnet50.6.3.conv3.weight', 139649784430416: 'resnet50.6.3.bn3.weight', 139649784428496: 'resnet50.6.3.bn3.bias', 139649784429296: 'resnet50.6.3.bn3.running_mean', 139649784430096: 'resnet50.6.3.bn3.running_var', 139649784428016: 'resnet50.6.3.bn3.num_batches_tracked', 139649757215312: 'resnet50.6.4.conv1.weight', 139651438651984: 'resnet50.6.4.bn1.weight', 139651438651344: 'resnet50.6.4.bn1.bias', 139651438650384: 'resnet50.6.4.bn1.running_mean', 139651312469088: 'resnet50.6.4.bn1.running_var', 139651312468288: 'resnet50.6.4.bn1.num_batches_tracked', 139649858694832: 'resnet50.6.4.conv2.weight', 139651312359936: 'resnet50.6.4.bn2.weight', 139649754219696: 'resnet50.6.4.bn2.bias', 139649784584944: 'resnet50.6.4.bn2.running_mean', 139649785173168: 'resnet50.6.4.bn2.running_var', 139651348334784: 'resnet50.6.4.bn2.num_batches_tracked', 139651348334144: 'resnet50.6.4.conv3.weight', 139649785052208: 'resnet50.6.4.bn3.weight', 139649785051888: 'resnet50.6.4.bn3.bias', 139651350426880: 'resnet50.6.4.bn3.running_mean', 139649783383216: 'resnet50.6.4.bn3.running_var', 139651350507344: 'resnet50.6.4.bn3.num_batches_tracked', 139651350503584: 'resnet50.6.5.conv1.weight', 139651306884144: 'resnet50.6.5.bn1.weight', 139649784265456: 'resnet50.6.5.bn1.bias', 139649784266496: 'resnet50.6.5.bn1.running_mean', 139649784265376: 'resnet50.6.5.bn1.running_var', 139649784266096: 'resnet50.6.5.bn1.num_batches_tracked', 139649784265936: 'resnet50.6.5.conv2.weight', 139649784266416: 'resnet50.6.5.bn2.weight', 139649784262896: 'resnet50.6.5.bn2.bias', 139649784263136: 'resnet50.6.5.bn2.running_mean', 139649784265136: 'resnet50.6.5.bn2.running_var', 139649784263856: 'resnet50.6.5.bn2.num_batches_tracked', 139649784266576: 'resnet50.6.5.conv3.weight', 139649784263376: 'resnet50.6.5.bn3.weight', 139649784264016: 'resnet50.6.5.bn3.bias', 139649784266656: 'resnet50.6.5.bn3.running_mean', 139651306528592: 'resnet50.6.5.bn3.running_var', 139651306528272: 'resnet50.6.5.bn3.num_batches_tracked', 139649783409392: 'resnet50.7.0.conv1.weight', 139649785440208: 'resnet50.7.0.bn1.weight', 139649785441648: 'resnet50.7.0.bn1.bias', 139649858764624: 'resnet50.7.0.bn1.running_mean', 139649858764464: 'resnet50.7.0.bn1.running_var', 139649750070448: 'resnet50.7.0.bn1.num_batches_tracked', 139649750070608: 'resnet50.7.0.conv2.weight', 139649750072528: 'resnet50.7.0.bn2.weight', 139649750070128: 'resnet50.7.0.bn2.bias', 139649750071728: 'resnet50.7.0.bn2.running_mean', 139649750071568: 'resnet50.7.0.bn2.running_var', 139649750070288: 'resnet50.7.0.bn2.num_batches_tracked', 139651308867408: 'resnet50.7.0.conv3.weight', 139651306563376: 'resnet50.7.0.bn3.weight', 139651306563616: 'resnet50.7.0.bn3.bias', 139651306565456: 'resnet50.7.0.bn3.running_mean', 139651306563056: 'resnet50.7.0.bn3.running_var', 139651306564736: 'resnet50.7.0.bn3.num_batches_tracked', 139651350320304: 'resnet50.7.0.downsample.0.weight', 139651350321584: 'resnet50.7.0.downsample.1.weight', 139651350322304: 'resnet50.7.0.downsample.1.bias', 139651350319184: 'resnet50.7.0.downsample.1.running_mean', 139651350322224: 'resnet50.7.0.downsample.1.running_var', 139651350319984: 'resnet50.7.0.downsample.1.num_batches_tracked', 139651350321104: 'resnet50.7.1.conv1.weight', 139651350321904: 'resnet50.7.1.bn1.weight', 139651350323024: 'resnet50.7.1.bn1.bias', 139651311349664: 'resnet50.7.1.bn1.running_mean', 139651311349424: 'resnet50.7.1.bn1.running_var', 139651311346944: 'resnet50.7.1.bn1.num_batches_tracked', 139651311346224: 'resnet50.7.1.conv2.weight', 139651311347184: 'resnet50.7.1.bn2.weight', 139651311346784: 'resnet50.7.1.bn2.bias', 139651311348544: 'resnet50.7.1.bn2.running_mean', 139651311346304: 'resnet50.7.1.bn2.running_var', 139649783634192: 'resnet50.7.1.bn2.num_batches_tracked', 139649783658448: 'resnet50.7.1.conv3.weight', 139651309182320: 'resnet50.7.1.bn3.weight', 139651309182800: 'resnet50.7.1.bn3.bias', 139651309180240: 'resnet50.7.1.bn3.running_mean', 139651309182640: 'resnet50.7.1.bn3.running_var', 139651309179760: 'resnet50.7.1.bn3.num_batches_tracked', 139651308414608: 'resnet50.7.2.conv1.weight', 139651307602000: 'resnet50.7.2.bn1.weight', 139651307604880: 'resnet50.7.2.bn1.bias', 139651307604080: 'resnet50.7.2.bn1.running_mean', 139651308670320: 'resnet50.7.2.bn1.running_var', 139651308667040: 'resnet50.7.2.bn1.num_batches_tracked', 139651309321744: 'resnet50.7.2.conv2.weight', 139651309321424: 'resnet50.7.2.bn2.weight', 139651309320304: 'resnet50.7.2.bn2.bias', 139651309320624: 'resnet50.7.2.bn2.running_mean', 139651307426352: 'resnet50.7.2.bn2.running_var', 139651307428272: 'resnet50.7.2.bn2.num_batches_tracked', 139651307429312: 'resnet50.7.2.conv3.weight', 139651307428672: 'resnet50.7.2.bn3.weight', 139651307427632: 'resnet50.7.2.bn3.bias', 139651308370592: 'resnet50.7.2.bn3.running_mean', 139651308370672: 'resnet50.7.2.bn3.running_var', 139651308370512: 'resnet50.7.2.bn3.num_batches_tracked', 139651311399712: 'encode_front_bbox.0.weight', 139651311399312: 'encode_front_bbox.0.bias', 139651312996912: 'encode_front_bbox.3.weight', 139651312996592: 'encode_front_bbox.3.bias', 139651307628016: 'encode_front_bbox.6.weight', 139652143972992: 'encode_front_bbox.6.bias', 139651348900272: 'decode_to_birdeye_bbox.0.weight', 139651313515888: 'decode_to_birdeye_bbox.0.bias', 139649858905584: 'decode_to_birdeye_bbox.3.weight', 139651308658112: 'decode_to_birdeye_bbox.3.bias', 139649784918896: 'decode_to_birdeye_bbox.6.weight', 139649784918416: 'decode_to_birdeye_bbox.6.bias', 139649758488848: 'decode_to_birdeye_bbox.9.weight', 139649758489568: 'decode_to_birdeye_bbox.9.bias', 139651436767104: 'decode_to_birdeye_bbox.12.weight', 139649858661424: 'decode_to_birdeye_bbox.12.bias', 139649858659984: 'decode_to_birdeye_bbox.15.weight', 139649858661264: 'decode_to_birdeye_bbox.15.bias'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Digraph.gv.pdf'"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs = torch.randn(1,3,224,224)\n",
    "# resnet18 = models.resnet18()\n",
    "# y = resnet18(Variable(inputs))\n",
    "# # print(y)\n",
    "\n",
    "# g = make_dot(y, resnet18.state_dict())\n",
    "# g.view()\n",
    "\n",
    "t_in = torch.randn(1,3,224,224 )\n",
    "t_in2 = torch.randn(1,4)\n",
    "y = model(Variable(t_in),Variable(t_in2))\n",
    "\n",
    "g = make_dot(y, model.state_dict())\n",
    "g.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipywidgets\n",
      "  Using cached ipywidgets-7.5.1-py2.py3-none-any.whl (121 kB)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from ipywidgets) (5.1.4)\n",
      "Collecting nbformat>=4.2.0\n",
      "  Using cached nbformat-5.0.4-py3-none-any.whl (169 kB)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from ipywidgets) (7.11.1)\n",
      "Collecting widgetsnbextension~=3.5.0\n",
      "  Using cached widgetsnbextension-3.5.1-py2.py3-none-any.whl (2.2 MB)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: tornado>=4.2 in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.0.3)\n",
      "Requirement already satisfied: jupyter-client in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from ipykernel>=4.5.1->ipywidgets) (5.3.4)\n",
      "Requirement already satisfied: jupyter-core in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets) (4.6.3)\n",
      "Requirement already satisfied: ipython-genutils in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from nbformat>=4.2.0->ipywidgets) (0.2.0)\n",
      "Collecting jsonschema!=2.5.0,>=2.4\n",
      "  Using cached jsonschema-3.2.0-py2.py3-none-any.whl (56 kB)\n",
      "Requirement already satisfied: setuptools>=18.5 in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (45.1.0)\n",
      "Requirement already satisfied: pickleshare in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: decorator in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.4.1)\n",
      "Requirement already satisfied: jedi>=0.10 in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.16.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (3.0.3)\n",
      "Requirement already satisfied: backcall in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.0)\n",
      "Requirement already satisfied: pygments in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.5.2)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.8.0)\n",
      "Collecting notebook>=4.4.1\n",
      "  Using cached notebook-6.0.3-py3-none-any.whl (9.7 MB)\n",
      "Requirement already satisfied: six in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from traitlets>=4.3.1->ipywidgets) (1.14.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (18.1.1)\n",
      "Collecting attrs>=17.4.0\n",
      "  Using cached attrs-19.3.0-py2.py3-none-any.whl (39 kB)\n",
      "Collecting pyrsistent>=0.14.0\n",
      "  Using cached pyrsistent-0.15.7.tar.gz (107 kB)\n",
      "Collecting importlib-metadata; python_version < \"3.8\"\n",
      "  Downloading importlib_metadata-1.5.0-py2.py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: parso>=0.5.2 in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: wcwidth in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.1.8)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/ali/.virtualenvs/py37/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.6.0)\n",
      "Collecting jinja2\n",
      "  Downloading Jinja2-2.11.1-py2.py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nbconvert\n",
      "  Using cached nbconvert-5.6.1-py2.py3-none-any.whl (455 kB)\n",
      "Collecting Send2Trash\n",
      "  Using cached Send2Trash-1.5.0-py3-none-any.whl (12 kB)\n",
      "Collecting prometheus-client\n",
      "  Using cached prometheus_client-0.7.1.tar.gz (38 kB)\n",
      "Collecting terminado>=0.8.1\n",
      "  Using cached terminado-0.8.3-py2.py3-none-any.whl (33 kB)\n",
      "Collecting zipp>=0.5\n",
      "  Downloading zipp-3.1.0-py3-none-any.whl (4.9 kB)\n",
      "Collecting MarkupSafe>=0.23\n",
      "  Downloading MarkupSafe-1.1.1-cp37-cp37m-manylinux1_x86_64.whl (27 kB)\n",
      "Collecting testpath\n",
      "  Using cached testpath-0.4.4-py2.py3-none-any.whl (163 kB)\n",
      "Collecting entrypoints>=0.2.2\n",
      "  Using cached entrypoints-0.3-py2.py3-none-any.whl (11 kB)\n",
      "Collecting mistune<2,>=0.8.1\n",
      "  Using cached mistune-0.8.4-py2.py3-none-any.whl (16 kB)\n",
      "Collecting defusedxml\n",
      "  Using cached defusedxml-0.6.0-py2.py3-none-any.whl (23 kB)\n",
      "Collecting bleach\n",
      "  Downloading bleach-3.1.1-py2.py3-none-any.whl (150 kB)\n",
      "\u001b[K     |████████████████████████████████| 150 kB 28.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandocfilters>=1.4.1\n",
      "  Using cached pandocfilters-1.4.2.tar.gz (14 kB)\n",
      "Collecting webencodings\n",
      "  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Building wheels for collected packages: pyrsistent, prometheus-client, pandocfilters\n",
      "  Building wheel for pyrsistent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyrsistent: filename=pyrsistent-0.15.7-cp37-cp37m-linux_x86_64.whl size=56531 sha256=646bcd44619d4228702ba5350a8f5cfed28f0e742b966f4ef4eea92e6427be91\n",
      "  Stored in directory: /home/ali/.cache/pip/wheels/57/74/e3/61db397ec89f304e49711ec9f68490f15814b80c1c0ee9b8c0\n",
      "  Building wheel for prometheus-client (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-py3-none-any.whl size=41402 sha256=7c9c976d314a7fd78bfd8bb354f9bdf49732844f9fccb8c05852f5cd51c07d28\n",
      "  Stored in directory: /home/ali/.cache/pip/wheels/30/0c/26/59ba285bf65dc79d195e9b25e2ddde4c61070422729b0cd914\n",
      "  Building wheel for pandocfilters (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pandocfilters: filename=pandocfilters-1.4.2-py3-none-any.whl size=7855 sha256=b3f2578599be2e0f0b9cf43da7a98a65e649ad26980dc2a712bde62905f1e727\n",
      "  Stored in directory: /home/ali/.cache/pip/wheels/63/99/01/9fe785b86d1e091a6b2a61e06ddb3d8eb1bc9acae5933d4740\n",
      "Successfully built pyrsistent prometheus-client pandocfilters\n",
      "Installing collected packages: attrs, pyrsistent, zipp, importlib-metadata, jsonschema, nbformat, MarkupSafe, jinja2, testpath, entrypoints, mistune, defusedxml, webencodings, bleach, pandocfilters, nbconvert, Send2Trash, prometheus-client, terminado, notebook, widgetsnbextension, ipywidgets\n",
      "Successfully installed MarkupSafe-1.1.1 Send2Trash-1.5.0 attrs-19.3.0 bleach-3.1.1 defusedxml-0.6.0 entrypoints-0.3 importlib-metadata-1.5.0 ipywidgets-7.5.1 jinja2-2.11.1 jsonschema-3.2.0 mistune-0.8.4 nbconvert-5.6.1 nbformat-5.0.4 notebook-6.0.3 pandocfilters-1.4.2 prometheus-client-0.7.1 pyrsistent-0.15.7 terminado-0.8.3 testpath-0.4.4 webencodings-0.5.1 widgetsnbextension-3.5.1 zipp-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e1c23f1c9894fafab558235cef1442b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/train-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fd20b59ff98426582a1a815f8d91644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/train-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac70fc83a9ff44a4aefb6d3b4e0fe0ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3657a457b6204692bba82d508a6c0a3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
      "Processing...\n",
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/torchvision/datasets/mnist.py:60: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n",
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/torchvision/datasets/mnist.py:50: UserWarning: test_labels has been renamed targets\n",
      "  warnings.warn(\"test_labels has been renamed targets\")\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import IntProgress\n",
    "import torch\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "\n",
    "resnet18 = models.resnet18(False)\n",
    "writer = SummaryWriter()\n",
    "sample_rate = 44100\n",
    "freqs = [262, 294, 330, 349, 392, 440, 440, 440, 440, 440, 440]\n",
    "\n",
    "for n_iter in range(100):\n",
    "\n",
    "    dummy_s1 = torch.rand(1)\n",
    "    dummy_s2 = torch.rand(1)\n",
    "    # data grouping by `slash`\n",
    "    writer.add_scalar('data/scalar1', dummy_s1[0], n_iter)\n",
    "    writer.add_scalar('data/scalar2', dummy_s2[0], n_iter)\n",
    "\n",
    "    writer.add_scalars('data/scalar_group', {'xsinx': n_iter * np.sin(n_iter),\n",
    "                                             'xcosx': n_iter * np.cos(n_iter),\n",
    "                                             'arctanx': np.arctan(n_iter)}, n_iter)\n",
    "\n",
    "    dummy_img = torch.rand(32, 3, 64, 64)  # output from network\n",
    "    if n_iter % 10 == 0:\n",
    "        x = vutils.make_grid(dummy_img, normalize=True, scale_each=True)\n",
    "        writer.add_image('Image', x, n_iter)\n",
    "\n",
    "        dummy_audio = torch.zeros(sample_rate * 2)\n",
    "        for i in range(x.size(0)):\n",
    "            # amplitude of sound should in [-1, 1]\n",
    "            dummy_audio[i] = np.cos(freqs[n_iter // 10] * np.pi * float(i) / float(sample_rate))\n",
    "        writer.add_audio('myAudio', dummy_audio, n_iter, sample_rate=sample_rate)\n",
    "\n",
    "        writer.add_text('Text', 'text logged at step:' + str(n_iter), n_iter)\n",
    "\n",
    "        for name, param in resnet18.named_parameters():\n",
    "            writer.add_histogram(name, param.clone().cpu().data.numpy(), n_iter)\n",
    "\n",
    "        # needs tensorboard 0.4RC or later\n",
    "        writer.add_pr_curve('xoxo', np.random.randint(2, size=100), np.random.rand(100), n_iter)\n",
    "\n",
    "dataset = datasets.MNIST('mnist', train=False, download=True)\n",
    "images = dataset.test_data[:100].float()\n",
    "label = dataset.test_labels[:100]\n",
    "\n",
    "features = images.view(100, 784)\n",
    "writer.add_embedding(features, metadata=label, label_img=images.unsqueeze(1))\n",
    "\n",
    "# export scalar data to JSON for external processing\n",
    "writer.export_scalars_to_json(\"./all_scalars.json\")\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
