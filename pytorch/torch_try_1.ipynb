{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib import Bkend_res50_8top\n",
    "from lib import Dataset_top_to_birdView\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "model = Bkend_res50_8top()\n",
    "t_in = torch.randn(1,3,224,224 )\n",
    "t_in2 = torch.randn(1,4)\n",
    "model(t_in,t_in2).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of removed labels:  0\n",
      "number of removed labels:  0\n"
     ]
    }
   ],
   "source": [
    "train_list = ['./data/train/000' ]\n",
    "val_list   = ['./data/val/000' ]\n",
    "\n",
    "training_generator     = Dataset_top_to_birdView( train_list )\n",
    "validation_generator   = Dataset_top_to_birdView( val_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_generator[0]\n",
    "\n",
    "train_loader = DataLoader(training_generator  ,batch_size=12 ,num_workers=12)\n",
    "val_loader   = DataLoader(validation_generator,batch_size=12 ,num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "writer = SummaryWriter('runs/bird_eyeview_experiment_1')\n",
    "\n",
    "# https://github.com/lanpa/tensorboardX\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "label_front, crop_front ,label_top = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(crop_front)\n",
    "\n",
    "writer.add_image('training_set_batches', img_grid)\n",
    "writer.add_graph(model,  (crop_front ,label_front))\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.93938350e-310, 4.94539712e-316, 2.84268732e-316, 2.84268693e-316])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_generator.bboxs_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this is good for classification task\n",
    "# https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
    "\n",
    "# # helper function\n",
    "# def select_n_random(data, labels, n=100):\n",
    "#     '''\n",
    "#     Selects n random datapoints and their corresponding labels from a dataset\n",
    "#     '''\n",
    "#     assert len(data) == len(labels)\n",
    "\n",
    "#     perm = torch.randperm(len(data))\n",
    "#     return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# # select random images and their target indices\n",
    "\n",
    "\n",
    "# images, labels = select_n_random(training_generator.imgs_f, training_generator.bboxs_b)\n",
    "\n",
    "# # get the class labels for each image\n",
    "# class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# # log embeddings\n",
    "# features = images.view(-1, 28 * 28)\n",
    "# writer.add_embedding(features,\n",
    "#                     metadata=class_labels,\n",
    "#                     label_img=images.unsqueeze(1))\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_loader))\n",
    "\n",
    "# for data in tqdm(train_loader):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1096,  0.0281,  0.0902, -0.0530],\n",
       "         [ 0.1311,  0.0051,  0.0787, -0.0649],\n",
       "         [ 0.1178,  0.0203,  0.0575, -0.0754],\n",
       "         [ 0.1310,  0.0187,  0.0758, -0.0623],\n",
       "         [ 0.1231,  0.0238,  0.0500, -0.0618],\n",
       "         [ 0.0988,  0.0235,  0.0669, -0.0482],\n",
       "         [ 0.1314,  0.0016,  0.0852, -0.0659],\n",
       "         [ 0.1153,  0.0199,  0.0832, -0.0713],\n",
       "         [ 0.1215,  0.0303,  0.0714, -0.0642],\n",
       "         [ 0.1335,  0.0231,  0.0972, -0.0661],\n",
       "         [ 0.1210,  0.0234,  0.0749, -0.0649],\n",
       "         [ 0.1268,  0.0265,  0.0939, -0.0681]], grad_fn=<TanhBackward>),\n",
       " tensor([[0.0150, 0.0060, 0.1930, 0.4270],\n",
       "         [0.0040, 0.2120, 0.1860, 0.6400],\n",
       "         [0.0750, 0.1440, 0.1550, 0.3800],\n",
       "         [0.0730, 0.3670, 0.1490, 0.5890],\n",
       "         [0.3340, 0.1120, 0.3950, 0.1730],\n",
       "         [0.2910, 0.0150, 0.3760, 0.2250],\n",
       "         [0.2530, 0.0040, 0.3580, 0.2860],\n",
       "         [0.2480, 0.0550, 0.3440, 0.3280],\n",
       "         [0.2470, 0.0930, 0.3330, 0.3550],\n",
       "         [0.2420, 0.1520, 0.3270, 0.4070],\n",
       "         [0.0210, 0.0360, 0.1140, 0.2540],\n",
       "         [0.2400, 0.1820, 0.3260, 0.4310]]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_front, crop_front ,label_top =  next(iter(train_loader))\n",
    "crop_front.shape\n",
    "model(crop_front,label_front) , label_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "model = model.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#     model = nn.DataParallel(model,device_ids=[0,1])\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# r = tqdm(train_loader)\n",
    "\n",
    "\n",
    "def train_(train_loader , epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    r = tqdm(train_loader)\n",
    "    for i, data in enumerate(r, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        label_front, crop_front ,label_top = data\n",
    "        label_front =label_front.to(device)\n",
    "        crop_front =crop_front.to(device)\n",
    "        label_top =label_top.to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(crop_front,label_front)\n",
    "        loss = criterion(outputs, label_top)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = copy.deepcopy(loss.item())\n",
    "        batch_loss = batch_loss / label_front.shape[0]\n",
    "        \n",
    "        writer.add_scalar('training batch loss',\n",
    "                        batch_loss ,\n",
    "                        epoch * len(train_loader) + i)\n",
    "        \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item() / len(train_loader)\n",
    "        \n",
    "        r.set_description(f'([T/{epoch}](L: {running_loss:0.6f} , BL{batch_loss: 0.6f})')\n",
    "        \n",
    "#         writer.close()\n",
    "        \n",
    "    writer.add_scalar('training loss',\n",
    "                        running_loss ,\n",
    "                        epoch )\n",
    "    writer.close()\n",
    "        \n",
    "    \n",
    "    \n",
    "def validation_ (val_loader , epoch):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    r2 = tqdm(val_loader)\n",
    "    for i, data in enumerate(r2, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        label_front, crop_front ,label_top = data\n",
    "        label_front =label_front.to(device)\n",
    "        crop_front =crop_front.to(device)\n",
    "        label_top =label_top.to(device)\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(crop_front,label_front)\n",
    "        loss = criterion(outputs, label_top)\n",
    "        \n",
    "        batch_loss = copy.deepcopy(loss.item())\n",
    "        batch_loss = batch_loss / label_front.shape[0]\n",
    "        \n",
    "        writer.add_scalar('validation batch loss',\n",
    "                        batch_loss ,\n",
    "                        epoch * len(val_loader) + i)\n",
    "        \n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item() / len(val_loader)\n",
    "        \n",
    "        r2.set_description(f'[E/{epoch}](L: {running_loss:0.6f} , BL{loss.item() / label_front.shape[0]: 0.6f})')\n",
    "        \n",
    "    writer.add_scalar('validation loss',\n",
    "                        running_loss ,\n",
    "                        epoch )\n",
    "    writer.close()\n",
    "        \n",
    "    return running_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Epoch 0 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22a2a9480714ce8ae5f7b6d7f3be998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5202bbc933a14489aefb5f35e79f7f30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E000_Loss0.149444.pt  is saved.\n",
      "============ Epoch 1 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76574c5c70dd49ba85a12e00dc3f678a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42372050a9e04841a8b9027b9e33cdcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E001_Loss0.114107.pt  is saved.\n",
      "============ Epoch 2 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2abfc7a60834ff3bfdf166f69142aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95486f21235c46e2811ce1346fc63e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E002_Loss0.090177.pt  is saved.\n",
      "============ Epoch 3 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2b71c03e95438b8df122fcf66d4760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e052bfcad3564607a674b5d31fcc4bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E003_Loss0.073898.pt  is saved.\n",
      "============ Epoch 4 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1002c745f4c644279fcd9314147f1334",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0463c86b20c14035abc3652cbf4a5cfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E004_Loss0.062870.pt  is saved.\n",
      "============ Epoch 5 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53a069af32049d480dbf1155af35434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bbc5c05185040838bd85097a9fa683e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E005_Loss0.055575.pt  is saved.\n",
      "============ Epoch 6 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca88ebd5e3fe4565922f3f8a28e75de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a94768278e405aac53fcefdffbce16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E006_Loss0.050835.pt  is saved.\n",
      "============ Epoch 7 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bac3c0d246ab4685b92f62e4e600515f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ee935ef1c7344e089c047683176a57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E007_Loss0.047844.pt  is saved.\n",
      "============ Epoch 8 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea988916963343fab0d989b72abc3322",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20717ce47ea04f008a8cacfbf719e396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E008_Loss0.046020.pt  is saved.\n",
      "============ Epoch 9 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ce8f1da943848ff98da4ce95bbac282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4dd9ac58c484269a98acefe839ae638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E009_Loss0.044951.pt  is saved.\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "best_loss = 1000000000;\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    print(f'============ Epoch {epoch} ============')\n",
    "    \n",
    "    train_(train_loader , epoch)\n",
    "    curr_val_loss = validation_ (val_loader , epoch)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "            writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
    "    writer.close()\n",
    "#     print('curr_val_loss' , curr_val_loss)\n",
    "    \n",
    "    \n",
    "\n",
    "    if curr_val_loss  < best_loss:\n",
    "        torch.save(model.state_dict(), f\"./model_E{epoch:03d}_Loss{curr_val_loss:.6f}.pt\")\n",
    "        print (f\"./model_E{epoch:03d}_Loss{curr_val_loss:.6f}.pt  is saved.\")\n",
    "        best_loss = curr_val_loss\n",
    "\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # show images\n",
    "# matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# # write to tensorboard\n",
    "# writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
