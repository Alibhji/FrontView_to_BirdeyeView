{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lib import Bkend_res50_8top\n",
    "from lib import Dataset_top_to_birdView\n",
    "from lib import train_ , validation_\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import copy\n",
    "\n",
    "\n",
    "\n",
    "model = Bkend_res50_8top()\n",
    "t_in = torch.randn(1,3,224,224 )\n",
    "t_in2 = torch.randn(1,4)\n",
    "model(t_in,t_in2).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of removed labels:  0\n",
      "number of removed labels:  0\n"
     ]
    }
   ],
   "source": [
    "train_list = ['./data/train/000' ]\n",
    "val_list   = ['./data/val/000' ]\n",
    "\n",
    "training_generator     = Dataset_top_to_birdView( train_list )\n",
    "validation_generator   = Dataset_top_to_birdView( val_list )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_generator[0]\n",
    "\n",
    "train_loader = DataLoader(training_generator  ,batch_size=12 ,num_workers=12)\n",
    "val_loader   = DataLoader(validation_generator,batch_size=12 ,num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ali/.virtualenvs/py37/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision\n",
    "writer = SummaryWriter('runs/bird_eyeview_experiment_1')\n",
    "\n",
    "# https://github.com/lanpa/tensorboardX\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "label_front, crop_front ,label_top = dataiter.next()\n",
    "\n",
    "# create grid of images\n",
    "img_grid = torchvision.utils.make_grid(crop_front)\n",
    "\n",
    "writer.add_image('training_set_batches', img_grid)\n",
    "writer.add_graph(model,  (crop_front ,label_front))\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_generator.bboxs_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#this is good for classification task\n",
    "# https://pytorch.org/tutorials/intermediate/tensorboard_tutorial.html\n",
    "\n",
    "# # helper function\n",
    "# def select_n_random(data, labels, n=100):\n",
    "#     '''\n",
    "#     Selects n random datapoints and their corresponding labels from a dataset\n",
    "#     '''\n",
    "#     assert len(data) == len(labels)\n",
    "\n",
    "#     perm = torch.randperm(len(data))\n",
    "#     return data[perm][:n], labels[perm][:n]\n",
    "\n",
    "# # select random images and their target indices\n",
    "\n",
    "\n",
    "# images, labels = select_n_random(training_generator.imgs_f, training_generator.bboxs_b)\n",
    "\n",
    "# # get the class labels for each image\n",
    "# class_labels = [classes[lab] for lab in labels]\n",
    "\n",
    "# # log embeddings\n",
    "# features = images.view(-1, 28 * 28)\n",
    "# writer.add_embedding(features,\n",
    "#                     metadata=class_labels,\n",
    "#                     label_img=images.unsqueeze(1))\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_loader))\n",
    "\n",
    "# for data in tqdm(train_loader):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_front, crop_front ,label_top =  next(iter(train_loader))\n",
    "# crop_front.shape\n",
    "# model(crop_front,label_front) , label_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \n",
    "model = model.to(device)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#     model = nn.DataParallel(model,device_ids=[0,1])\n",
    "    model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # r = tqdm(train_loader)\n",
    "\n",
    "\n",
    "# def train_(train_loader , epoch):\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     r = tqdm(train_loader)\n",
    "#     for i, data in enumerate(r, 0):\n",
    "#         # get the inputs; data is a list of [inputs, labels]\n",
    "#         label_front, crop_front ,label_top = data\n",
    "#         label_front =label_front.to(device)\n",
    "#         crop_front =crop_front.to(device)\n",
    "#         label_top =label_top.to(device)\n",
    "\n",
    "#         # zero the parameter gradients\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = model(crop_front,label_front)\n",
    "#         loss = criterion(outputs, label_top)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         batch_loss = copy.deepcopy(loss.item())\n",
    "#         batch_loss = batch_loss / label_front.shape[0]\n",
    "        \n",
    "#         writer.add_scalar('training batch loss',\n",
    "#                         batch_loss ,\n",
    "#                         epoch * len(train_loader) + i)\n",
    "        \n",
    "\n",
    "#         # print statistics\n",
    "#         running_loss += loss.item() / len(train_loader)\n",
    "        \n",
    "#         r.set_description(f'([T/{epoch}](L: {running_loss:0.6f} , BL{batch_loss: 0.6f})')\n",
    "        \n",
    "# #         writer.close()\n",
    "        \n",
    "#     writer.add_scalar('training loss',\n",
    "#                         running_loss ,\n",
    "#                         epoch )\n",
    "#     writer.close()\n",
    "        \n",
    "    \n",
    "    \n",
    "# def validation_ (val_loader , epoch):\n",
    "#     model.eval()\n",
    "#     running_loss = 0.0\n",
    "#     r2 = tqdm(val_loader)\n",
    "#     for i, data in enumerate(r2, 0):\n",
    "#         # get the inputs; data is a list of [inputs, labels]\n",
    "#         label_front, crop_front ,label_top = data\n",
    "#         label_front =label_front.to(device)\n",
    "#         crop_front =crop_front.to(device)\n",
    "#         label_top =label_top.to(device)\n",
    "\n",
    "#         # forward + backward + optimize\n",
    "#         outputs = model(crop_front,label_front)\n",
    "#         loss = criterion(outputs, label_top)\n",
    "        \n",
    "#         batch_loss = copy.deepcopy(loss.item())\n",
    "#         batch_loss = batch_loss / label_front.shape[0]\n",
    "        \n",
    "#         writer.add_scalar('validation batch loss',\n",
    "#                         batch_loss ,\n",
    "#                         epoch * len(val_loader) + i)\n",
    "        \n",
    "\n",
    "#         # print statistics\n",
    "#         running_loss += loss.item() / len(val_loader)\n",
    "        \n",
    "#         r2.set_description(f'[E/{epoch}](L: {running_loss:0.6f} , BL{loss.item() / label_front.shape[0]: 0.6f})')\n",
    "        \n",
    "#     writer.add_scalar('validation loss',\n",
    "#                         running_loss ,\n",
    "#                         epoch )\n",
    "#     writer.close()\n",
    "        \n",
    "#     return running_loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============ Epoch 0 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e652bd53ab14442b900fb703dd8b630a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16c8bb30cccf459bb107d85b38535337",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E000_Loss0.152834.pt  is saved.\n",
      "============ Epoch 1 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf6732621c9a455a8a8632b21156c62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "193c1b4f0c3e457c8b64ea4fa388c654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E001_Loss0.115850.pt  is saved.\n",
      "============ Epoch 2 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a88ab9221ad4ea6901bef3061d97dd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e8194e681cb4431bf6530ffc1e2538a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E002_Loss0.091529.pt  is saved.\n",
      "============ Epoch 3 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6843e75624b145c097dcc98ba7825cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7311b56e721046ca9461f228c4966517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E003_Loss0.075493.pt  is saved.\n",
      "============ Epoch 4 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "792f4ebdc5ca40e88a18c9ac272a4986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04936cb09cf344e794dd8ceaa426f5b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E004_Loss0.064877.pt  is saved.\n",
      "============ Epoch 5 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "468f43f407d84c7badf4072da4a2b75b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a407d1f0756147459d9a66e7d440e3dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E005_Loss0.057762.pt  is saved.\n",
      "============ Epoch 6 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b767ffaab5e04c2eb98a10b41d1a1905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b72c01d96634a0286f269ed096e251c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E006_Loss0.052971.pt  is saved.\n",
      "============ Epoch 7 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce200835b4f2497d8b41b83dd67583c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be0c4f2a38ff4fc99d364ecd5394d70c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E007_Loss0.049777.pt  is saved.\n",
      "============ Epoch 8 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897e921ed40c47d1979c8c4e306b0150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34bb0f82c3304024918b8067a63f83b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E008_Loss0.047671.pt  is saved.\n",
      "============ Epoch 9 ============\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "698af85d87644c9b810179f1bd4eaa73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=273.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff8a27732b414851a7cd5bf8da42bbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=320.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "./model_E009_Loss0.046312.pt  is saved.\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "best_loss = 1000000000;\n",
    "\n",
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "    print(f'============ Epoch {epoch} ============')\n",
    "    \n",
    "    train_(model ,\n",
    "           train_loader ,\n",
    "           epoch,\n",
    "           device=device,criterion=criterion ,\n",
    "           optimizer=optimizer,\n",
    "           writer=writer)\n",
    "    \n",
    "    curr_val_loss =\\\n",
    "    validation_ (model \n",
    "                 ,val_loader , \n",
    "                 epoch ,device=device,\n",
    "                 criterion=criterion ,\n",
    "                 writer=writer)\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "            writer.add_histogram(name, param.clone().cpu().data.numpy(), epoch)\n",
    "    writer.close()\n",
    "#     print('curr_val_loss' , curr_val_loss)\n",
    "    \n",
    "    \n",
    "\n",
    "    if curr_val_loss  < best_loss:\n",
    "        torch.save(model.state_dict(), f\"./model_E{epoch:03d}_Loss{curr_val_loss:.6f}.pt\")\n",
    "        print (f\"./model_E{epoch:03d}_Loss{curr_val_loss:.6f}.pt  is saved.\")\n",
    "        best_loss = curr_val_loss\n",
    "\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # show images\n",
    "# matplotlib_imshow(img_grid, one_channel=True)\n",
    "\n",
    "# # write to tensorboard\n",
    "# writer.add_image('four_fashion_mnist_images', img_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
